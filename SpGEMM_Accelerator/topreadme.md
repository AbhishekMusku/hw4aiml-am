# ** [Complete Project Journal & Documentation](https://github.com/AbhishekMusku/hw4aiml-am/wiki/Project-%E2%80%90-SpGEMM-Accelerator)**

## **ðŸ”— Comprehensive Development Timeline & Architecture Analysis**

**ðŸ“– [Access the full project wiki here](https://github.com/AbhishekMusku/hw4aiml-am/wiki/Project-%E2%80%90-SpGEMM-Accelerator)** - This ***version-controlled journal has been meticulously updated from the start of the course to the end*** documenting every aspect of the project development timeline.

**The wiki contains comprehensive documentation including:**
- **Architecture & Design Trade-offs**: Chiplet partitioning, communication protocols, memory hierarchy decisions with thorough justification
- **Technical Specifications**: Timing diagrams, SPI interface protocols, and system integration analysis
- **Vibecoding Prompts**: Complete reproducibility instructions for replicating all results
- **Weekly Progress Updates**: ***Version-controlled timeline showing project evolution from initial concept through final implementation***

## ** Component Documentation Links**

- **[ Python-Only Implementation Documentation](https://github.com/AbhishekMusku/hw4aiml-am/blob/main/SpGEMM_Accelerator/01_python_software_only/readme.md)** - Software baseline and algorithm validation
- **[ Standalone SpGEMM Hardware Accelerator Documentation](https://github.com/AbhishekMusku/hw4aiml-am/blob/main/SpGEMM_Accelerator/02_rtl_only/readme.md)** - RTL-only MatRaptor core verification
- **[ Coprocessor Documentation](https://github.com/AbhishekMusku/hw4aiml-am/blob/main/SpGEMM_Accelerator/03_coprocessor/readme.md)** - Complete hardware-software integration
- **[ Vibe Coding Prompts Collection](https://github.com/AbhishekMusku/hw4aiml-am/tree/main/SpGEMM_Accelerator/07_docs)** - Complete LLM prompts and AI assistance documentation for reproducibility

## ** AI-Assisted Development Acknowledgment**

This project extensively utilized Large Language Models for "vibe coding" and development assistance:
- **ChatGPT** (OpenAI), **Claude** (Anthropic), **Gemini** (Google)

*All AI-generated code was thoroughly reviewed, tested, and integrated. LLM assistance enabled rapid prototyping and exploration of design alternatives.*

---

# MatRaptor Collaborative Filtering Coprocessor

A hardware-accelerated system for real-time movie recommendation using sparse matrix multiplication and the MatRaptor architecture.

## Project Overview

### What is Collaborative Filtering?

Collaborative filtering is a method used by recommendation systems to suggest items (like movies, products, or content) to users based on the preferences of similar users. The core idea is simple: *"Users who agreed in the past will agree in the future"*.

**How It Works for Movie Recommendations:**

1. **User-Item Matrix**: We start with a matrix where rows represent users, columns represent movies, and values represent ratings (1-5 stars)
2. **Item Similarity**: We calculate how similar movies are to each other based on user ratings
3. **Predictions**: For a user who hasn't seen a movie, we predict their rating based on:
   - Movies they have rated
   - How similar those movies are to the target movie
4. **Recommendations**: We recommend movies with the highest predicted ratings

**Example:**
```
         Movie A  Movie B  Movie C
User 1      5       3       ?     â† Predict this
User 2      4       2       4
User 3      5       3       4
```

If Movie A and Movie C are highly similar (both users who liked A also liked C), we'd predict User 1 would rate Movie C highly.

### Our MatRaptor Implementation

Traditional collaborative filtering becomes computationally expensive with large datasets (millions of users Ã— millions of movies). Our system accelerates the most compute-intensive part - **calculating item-to-item similarity** - using a custom hardware coprocessor based on the MatRaptor sparse matrix multiplication architecture.

**Key Innovation**: Instead of using general-purpose processors, we use specialized hardware optimized for sparse matrix operations, achieving significant speedup for real-time recommendation systems.

## System Architecture

![MatRaptor Coprocessor Architecture](image.png)

The system implements a complete hardware-software pipeline:

**Software Domain (Python):**
- **Preprocessing** (`cob_part1.py`): Loads user-item matrices, normalizes data, generates partial products
- **Post-processing** (`cob_part3.py`): Takes hardware-computed similarity matrix and generates final recommendations

**Hardware Domain (SystemVerilog):**
- **SPI Interface**: Receives partial products via 72-bit frames from Python
- **MatRaptor Core**: Specialized PE with 8 queues performing sparse matrix multiplication using row-wise products
- **Output Stream**: Produces item similarity matrix for collaborative filtering

**Verification Framework (CocoTB):**
- **End-to-end Testing**: Orchestrates complete pipeline from Python preprocessing through hardware to final recommendations
- **Golden Model Validation**: Ensures hardware results match software-only implementation

## Hardware Coprocessor Details

### MatRaptor Core Architecture

Our coprocessor implements a **single Processing Element (PE)** optimized for sparse-sparse matrix multiplication:

**Core Specifications:**
- **8 Parallel Queues**: Column-wise data organization with direct addressing
- **256 Entries/Queue**: Supports matrix columns 0-2047 (8 Ã— 256)
- **500 MHz Operation**: 2ns clock period for high-throughput processing
- **Direct Column Mapping**: `queue_id = column[10:8]`, `address = column[7:0]`

**Processing Pipeline:**
1. **Fill Phase**: Stream partial products with automatic accumulation for duplicate columns
2. **Merge Phase**: Bitmap-based sorted output generation across all queues
3. **Row-Wise Processing**: Continuous multi-row support with automatic boundary detection

**Memory Organization:**
```systemverilog
// Each queue entry contains:
typedef struct packed {
    logic                valid;    // Position validity
    logic [31:0]         val;      // Accumulated value  
    logic [15:0]         col;      // Column index
} entry_t;

entry_t queue_mem[8][256];  // 8 queues Ã— 256 entries
```

### SPI Communication Interface

**Frame Format** (9 bytes = 72 bits):
```
Bit Position:  71    40  39    24  23     8  7      0
              â”‚ VALUE â”‚   ROW   â”‚   COL   â”‚ FLAGS  â”‚
              â”‚ 32b   â”‚   16b   â”‚   16b   â”‚   8b   â”‚
```

**Performance Characteristics:**
- **SPI Throughput**: ~23.68 Mbps sustained transfer rate
- **Frame Processing**: 347K frames/second capability
- **Clock Domain Crossing**: Robust toggle-based synchronizer (SPI â†’ 500MHz system clock)

## Project Structure

```
MatRaptor_Collaborative_Filtering/
â”œâ”€â”€ 01_python_software_only/           # Software-only baseline implementations
â”‚   â”œâ”€â”€ COB_advanced/                  # Advanced collaborative filtering algorithms
â”‚   â”‚   â”œâ”€â”€ datasets/                  # Test datasets (250, 500, 750)
â”‚   â”‚   â””â”€â”€ dataset_gen/               # Dataset generation utilities
â”‚   â”œâ”€â”€ COB_base/                      # Basic collaborative filtering implementation
â”‚   â”‚   â”œâ”€â”€ datasets/                  # Test datasets (250, 500, 750)
â”‚   â”‚   â””â”€â”€ hide/                      # Hidden/auxiliary files
â”‚   â””â”€â”€ COB_coprocessor_benchmarking_only/  # Performance benchmarking suite
â”‚       â”œâ”€â”€ 250/                       # 250Ã—250 benchmark data
â”‚       â”œâ”€â”€ 500/                       # 500Ã—500 benchmark data
â”‚       â””â”€â”€ 750/                       # 750Ã—750 benchmark data
â”œâ”€â”€ 02_rtl_only/                       # RTL verification and testing
â”‚   â”œâ”€â”€ Matrix_Multiplication_Verifier/ # Hardware verification framework
â”‚   â””â”€â”€ Tests/                         # RTL test suites
â”‚       â”œâ”€â”€ 1000/                      # 1000Ã—1000 matrix tests
â”‚       â”œâ”€â”€ 1500/                      # 1500Ã—1500 matrix tests
â”‚       â”œâ”€â”€ 2000/                      # 2000Ã—2000 matrix tests
â”‚       â””â”€â”€ 500/                       # 500Ã—500 matrix tests
â”œâ”€â”€ 03_coprocessor/                    # Main hardware-software coprocessor
â”‚   â”œâ”€â”€ datasets/
â”‚   â”‚   â”œâ”€â”€ 50/                        # Small test dataset (50Ã—50)
â”‚   â”‚   â””â”€â”€ 250/                       # Medium dataset (250Ã—250)
â”‚   â”œâ”€â”€ verification/                  # Golden model validation
â”‚   â”œâ”€â”€ Matraptor.sv                   # Core hardware implementation
â”‚   â”œâ”€â”€ simple_spi_interface.sv        # SPI communication layer
â”‚   â”œâ”€â”€ tb_matraptor_core.sv          # SystemVerilog testbench
â”‚   â”œâ”€â”€ test_spi.py                    # CocoTB orchestration
â”‚   â”œâ”€â”€ cob_part1.py                   # Preprocessing pipeline
â”‚   â”œâ”€â”€ cob_part3.py                   # Post-processing & recommendations
â”‚   â”œâ”€â”€ analyze_results.py             # Performance analysis
â”‚   â””â”€â”€ Makefile                       # Build automation
â”œâ”€â”€ 04_synthesis/                      # ASIC synthesis and implementation
â”‚   â”œâ”€â”€ outputs/                       # Synthesis output files
â”‚   â”œâ”€â”€ reports/                       # Timing, area, power reports
â”‚   â”œâ”€â”€ rtl/                          # RTL libraries and work files
â”‚   â”‚   â”œâ”€â”€ alib-52/                   # Standard cell library
â”‚   â”‚   â”œâ”€â”€ hide/                      # Hidden synthesis files
â”‚   â”‚   â””â”€â”€ work/                      # Synthesis workspace
â”‚   â”œâ”€â”€ scripts/                       # Synthesis automation scripts
â”‚   â””â”€â”€ work/                          # Additional synthesis workspace
â”‚       â””â”€â”€ alib-52/                   # Library work area
â”œâ”€â”€ 05_initial_profiling/              # Early performance profiling results
â”œâ”€â”€ 06_literature_survey/              # Research papers and background materials
â””â”€â”€ 07_docs/                          # Project documentation and reports
```

## Installation & Setup

### Prerequisites

**Software Requirements:**
- **QuestaSim/ModelSim**: SystemVerilog simulation environment
- **Python 3.6+**: With scientific computing libraries
- **CocoTB**: Hardware verification framework
- **Make**: Build automation

**Python Dependencies:**
```bash
pip install numpy pandas scipy cocotb
```

### Quick Start Guide

#### 1. Choose Your Dataset

```bash
cd 03_coprocessor/

# For rapid testing (50Ã—50 matrix - ~2 seconds)
cp datasets/50/user_item_matrix_complete.csv user_item_matrix_complete.csv

# For performance evaluation (250Ã—250 matrix - ~30 seconds)  
cp datasets/250/user_item_matrix_complete.csv user_item_matrix_complete.csv
```

**Dataset Format:**
```csv
user_id,item_id,rating
0,0,4.5
0,5,3.2
1,2,5.0
...
```

#### 2. Execute Complete Pipeline

Run the entire collaborative filtering pipeline with hardware acceleration:

```bash
# Single command runs: preprocessing â†’ hardware simulation â†’ post-processing
make | tee sim.log
```

**Pipeline Stages Executed:**
1. **Preprocessing**: `cob_part1.py` normalizes data and generates partial products (`in.csv`)
2. **Hardware Simulation**: CocoTB streams data via SPI to MatRaptor core
3. **Sparse Matrix Multiplication**: Hardware computes item similarity matrix
4. **Output Generation**: Results written to `out.csv`
5. **Post-processing**: `cob_part3.py` generates recommendations (`recommendations.csv`)

#### 3. Analyze Performance Results

```bash
# Generate comprehensive performance analysis
python3 analyze_results.py
```

### Expected Output Files

After successful execution:

```
03_coprocessor/
â”œâ”€â”€ sim.log                          # Complete simulation transcript
â”œâ”€â”€ in.csv                          # Hardware input (partial products)  
â”œâ”€â”€ out.csv                         # Hardware output (similarity matrix)
â”œâ”€â”€ recommendations.csv             # Final user recommendations
â”œâ”€â”€ performance_stats.csv           # Collaborative filtering metrics
â”œâ”€â”€ cob1_timing_stats.csv          # Preprocessing timing
â””â”€â”€ final_pipeline_summary.csv     # Complete performance summary
```

## Performance Results

### Benchmark: 250Ã—250 Movie Rating Matrix

**Hardware Accelerator Performance:**
- **SpGEMM Execution Time**: 126.8 milliseconds
- **Frames Processed**: 41,719 partial products
- **SPI Throughput**: 23.68 Mbps sustained
- **Total Pipeline Time**: 192.6 milliseconds

**Performance Breakdown:**
- Software Preprocessing: 50.7ms (26.3%)
- **Hardware Execution: 126.8ms (65.8%)**
- Software Post-processing: 15.1ms (7.8%)

**Speedup Analysis:**
- **68.6Ã— speedup** over dense matrix baseline
- Establishes foundation for multi-PE scaling
- Demonstrates viability of specialized hardware for recommendation systems

### Collaborative Filtering Quality

**Recommendation Accuracy:**
- **100% algorithmic correctness** via golden model validation
- Identical recommendations to software-only implementation
- Maintains floating-point precision through 16-bit fixed-point scaling

## Verification & Validation

### Automated Correctness Validation

```bash
cd verification/
python3 verifier.py
```

**Verification Process:**
- **Golden Reference**: Software-only collaborative filtering implementation
- **Hardware Results**: Coprocessor-generated recommendations
- **Comparison**: ID matching, rating validation, statistical analysis

**Success Indicators:**
- âœ… Same (user_id, item_id) pairs recommended
- âœ… Predicted ratings match within tolerance
- âœ… Overall recommendation quality preserved

## Troubleshooting

**Common Issues:**

1. **Simulation Timeout**: Increase timeout in `test_spi.py` for larger datasets
2. **SPI Frame Errors**: Check SPI timing and frame format in `sim.log`
3. **Python Import Errors**: Ensure scipy, pandas, numpy are installed
4. **File Not Found**: Verify dataset CSV files exist and are properly formatted

**Debug Commands:**
```bash
# View SPI communication details
grep "\[SPI\]" sim.log

# Check hardware state transitions  
grep "\[TB STATE\]" sim.log

# Monitor timing measurements
grep "TIMING" sim.log
```

## Research Context

This implementation is based on the MatRaptor paper:
> *"MatRaptor: A Sparse-Sparse Matrix Multiplication Accelerator Based on Row-Wise Product"* - Srivastava et al., MICRO 2020

Our contribution applies MatRaptor's row-wise product approach to collaborative filtering, demonstrating practical acceleration of machine learning workloads using specialized sparse matrix hardware.

---

**For detailed technical specifications, see individual component documentation in the respective source files.**